{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# An√°lisis de Estaci√≥n Individual - Enfoque Simplificado\n",
        "\n",
        "## üìã Objetivo\n",
        "An√°lisis detallado de los modelos entrenados para predecir arribos a la **Estaci√≥n 014 - Pacifico** usando el enfoque simplificado.\n",
        "\n",
        "### üéØ Comparaciones a Realizar:\n",
        "1. **Modelo Global** vs **Modelo Estaciones Cercanas**\n",
        "2. **Feature Importance** de ambos enfoques\n",
        "3. **An√°lisis temporal** de predicciones\n",
        "4. **Distribuci√≥n de errores** por rangos de valores\n",
        "5. **Visualizaciones** de performance\n",
        "\n",
        "### üìä Estaci√≥n Objetivo:\n",
        "- **ID:** 14\n",
        "- **Nombre:** 014 - Pacifico  \n",
        "- **Ubicaci√≥n:** Lat -34.577423, Long -58.426388\n",
        "- **Es la estaci√≥n m√°s concurrida** del sistema EcoBici\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuraci√≥n e imports\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('../scripts')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurar matplotlib\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 10\n",
        "\n",
        "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
        "print(f\"üìç Directorio actual: {os.getcwd()}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîÑ 1. Carga de Modelos y Datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funci√≥n para cargar modelos\n",
        "def load_model_safe(model_path):\n",
        "    \"\"\"Carga un modelo de forma segura\"\"\"\n",
        "    try:\n",
        "        with open(model_path, 'rb') as f:\n",
        "            model_info = pickle.load(f)\n",
        "        print(f\"‚úÖ Modelo cargado: {model_path}\")\n",
        "        return model_info\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå No se encontr√≥: {model_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error cargando {model_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Cargar modelos entrenados\n",
        "global_model = load_model_safe('../models/xgboost_global_features.pkl')\n",
        "nearby_model = load_model_safe('../models/xgboost_nearby_features.pkl')\n",
        "\n",
        "print(\"\\nüìä INFORMACI√ìN DE MODELOS:\")\n",
        "if global_model:\n",
        "    print(f\"üåê Global - R¬≤: {global_model['metrics']['val_r2']:.4f}, Features: {len(global_model['features'])}\")\n",
        "if nearby_model:\n",
        "    print(f\"üîç Cercanas - R¬≤: {nearby_model['metrics']['val_r2']:.4f}, Features: {len(nearby_model['features'])}\")\n",
        "\n",
        "# Cargar datasets de validaci√≥n\n",
        "print(\"\\nüìÇ Cargando datasets...\")\n",
        "val_global = pd.read_csv('../data/val_global.csv')\n",
        "val_nearby = pd.read_csv('../data/val_nearby.csv')\n",
        "\n",
        "print(f\"‚úÖ Val Global: {val_global.shape}\")\n",
        "print(f\"‚úÖ Val Cercanas: {val_nearby.shape}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìä 2. Comparaci√≥n de M√©tricas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparaci√≥n de m√©tricas\n",
        "def create_metrics_comparison():\n",
        "    \"\"\"Crea una comparaci√≥n visual de las m√©tricas\"\"\"\n",
        "    \n",
        "    if not global_model or not nearby_model:\n",
        "        print(\"‚ùå No se pueden comparar modelos - algunos no est√°n disponibles\")\n",
        "        return\n",
        "    \n",
        "    # Extraer m√©tricas\n",
        "    metrics_data = {\n",
        "        'Modelo': ['Global', 'Cercanas'],\n",
        "        'R¬≤': [global_model['metrics']['val_r2'], nearby_model['metrics']['val_r2']],\n",
        "        'RMSE': [global_model['metrics']['val_rmse'], nearby_model['metrics']['val_rmse']],\n",
        "        'MAE': [global_model['metrics']['val_mae'], nearby_model['metrics']['val_mae']],\n",
        "        'Features': [len(global_model['features']), len(nearby_model['features'])]\n",
        "    }\n",
        "    \n",
        "    df_metrics = pd.DataFrame(metrics_data)\n",
        "    \n",
        "    # Crear visualizaci√≥n\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('üÜö Comparaci√≥n de Modelos: Global vs Estaciones Cercanas', fontsize=16)\n",
        "    \n",
        "    # R¬≤\n",
        "    ax1 = axes[0,0]\n",
        "    bars1 = ax1.bar(df_metrics['Modelo'], df_metrics['R¬≤'], \n",
        "                    color=['steelblue', 'orange'], alpha=0.7)\n",
        "    ax1.set_title('R¬≤ Score (Mayor es Mejor)', fontsize=12)\n",
        "    ax1.set_ylabel('R¬≤')\n",
        "    ax1.set_ylim(0, max(df_metrics['R¬≤']) * 1.1)\n",
        "    \n",
        "    # Agregar valores en las barras\n",
        "    for bar, value in zip(bars1, df_metrics['R¬≤']):\n",
        "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{value:.3f}', ha='center', va='bottom')\n",
        "    \n",
        "    # RMSE\n",
        "    ax2 = axes[0,1]\n",
        "    bars2 = ax2.bar(df_metrics['Modelo'], df_metrics['RMSE'], \n",
        "                    color=['steelblue', 'orange'], alpha=0.7)\n",
        "    ax2.set_title('RMSE (Menor es Mejor)', fontsize=12)\n",
        "    ax2.set_ylabel('RMSE')\n",
        "    \n",
        "    # Agregar valores en las barras\n",
        "    for bar, value in zip(bars2, df_metrics['RMSE']):\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
        "                f'{value:.2f}', ha='center', va='bottom')\n",
        "    \n",
        "    # MAE\n",
        "    ax3 = axes[1,0]\n",
        "    bars3 = ax3.bar(df_metrics['Modelo'], df_metrics['MAE'], \n",
        "                    color=['steelblue', 'orange'], alpha=0.7)\n",
        "    ax3.set_title('MAE (Menor es Mejor)', fontsize=12)\n",
        "    ax3.set_ylabel('MAE')\n",
        "    \n",
        "    # Agregar valores en las barras\n",
        "    for bar, value in zip(bars3, df_metrics['MAE']):\n",
        "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,\n",
        "                f'{value:.2f}', ha='center', va='bottom')\n",
        "    \n",
        "    # N√∫mero de Features\n",
        "    ax4 = axes[1,1]\n",
        "    bars4 = ax4.bar(df_metrics['Modelo'], df_metrics['Features'], \n",
        "                    color=['steelblue', 'orange'], alpha=0.7)\n",
        "    ax4.set_title('N√∫mero de Features', fontsize=12)\n",
        "    ax4.set_ylabel('Cantidad de Features')\n",
        "    \n",
        "    # Agregar valores en las barras\n",
        "    for bar, value in zip(bars4, df_metrics['Features']):\n",
        "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
        "                f'{value}', ha='center', va='bottom')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Tabla resumen\n",
        "    print(\"\\nüìã TABLA RESUMEN DE M√âTRICAS:\")\n",
        "    print(\"=\"*60)\n",
        "    print(df_metrics.to_string(index=False, float_format='%.4f'))\n",
        "    \n",
        "    # An√°lisis\n",
        "    r2_diff = nearby_model['metrics']['val_r2'] - global_model['metrics']['val_r2']\n",
        "    feature_reduction = (1 - len(nearby_model['features']) / len(global_model['features'])) * 100\n",
        "    \n",
        "    print(f\"\\nüîç AN√ÅLISIS:\")\n",
        "    print(f\"   Diferencia R¬≤: {r2_diff:+.4f}\")\n",
        "    print(f\"   Reducci√≥n features: {feature_reduction:.1f}%\")\n",
        "    \n",
        "    if r2_diff > 0.01:\n",
        "        print(\"üéâ ¬°Modelo CERCANAS es significativamente mejor!\")\n",
        "    elif r2_diff > -0.01:\n",
        "        print(\"ü§ù Performance similar entre ambos modelos\")\n",
        "    else:\n",
        "        print(\"üåê Modelo GLOBAL tiene mejor performance\")\n",
        "\n",
        "create_metrics_comparison()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîù 3. Feature Importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# An√°lisis de Feature Importance\n",
        "def plot_feature_importance():\n",
        "    \"\"\"Compara la importancia de features entre ambos modelos\"\"\"\n",
        "    \n",
        "    if not global_model or not nearby_model:\n",
        "        print(\"‚ùå No se pueden analizar features - modelos no disponibles\")\n",
        "        return\n",
        "    \n",
        "    # Extraer feature importance\n",
        "    global_features = global_model['features']\n",
        "    global_importance = global_model['model'].feature_importances_\n",
        "    \n",
        "    nearby_features = nearby_model['features']\n",
        "    nearby_importance = nearby_model['model'].feature_importances_\n",
        "    \n",
        "    # Crear DataFrames\n",
        "    df_global = pd.DataFrame({\n",
        "        'feature': global_features,\n",
        "        'importance': global_importance,\n",
        "        'model': 'Global'\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    df_nearby = pd.DataFrame({\n",
        "        'feature': nearby_features,\n",
        "        'importance': nearby_importance,\n",
        "        'model': 'Cercanas'\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    # Visualizar top features\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "    \n",
        "    # Top features modelo global\n",
        "    top_global = df_global.head(15)\n",
        "    ax1.barh(range(len(top_global)), top_global['importance'], color='steelblue', alpha=0.7)\n",
        "    ax1.set_yticks(range(len(top_global)))\n",
        "    ax1.set_yticklabels(top_global['feature'])\n",
        "    ax1.set_xlabel('Importancia')\n",
        "    ax1.set_title('üåê Top 15 Features - Modelo Global')\n",
        "    ax1.invert_yaxis()\n",
        "    \n",
        "    # Top features modelo cercanas\n",
        "    top_nearby = df_nearby.head(15)\n",
        "    ax2.barh(range(len(top_nearby)), top_nearby['importance'], color='orange', alpha=0.7)\n",
        "    ax2.set_yticks(range(len(top_nearby)))\n",
        "    ax2.set_yticklabels(top_nearby['feature'])\n",
        "    ax2.set_xlabel('Importancia')\n",
        "    ax2.set_title('üîç Top 15 Features - Modelo Cercanas')\n",
        "    ax2.invert_yaxis()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # An√°lisis de features en com√∫n\n",
        "    common_features = set(global_features) & set(nearby_features)\n",
        "    print(f\"\\nüîó FEATURES EN COM√öN: {len(common_features)}\")\n",
        "    \n",
        "    if common_features:\n",
        "        # Comparar importancia de features comunes\n",
        "        common_comparison = []\n",
        "        for feature in common_features:\n",
        "            global_imp = df_global[df_global['feature'] == feature]['importance'].iloc[0]\n",
        "            nearby_imp = df_nearby[df_nearby['feature'] == feature]['importance'].iloc[0]\n",
        "            common_comparison.append({\n",
        "                'feature': feature,\n",
        "                'global_importance': global_imp,\n",
        "                'nearby_importance': nearby_imp,\n",
        "                'difference': nearby_imp - global_imp\n",
        "            })\n",
        "        \n",
        "        df_common = pd.DataFrame(common_comparison).sort_values('nearby_importance', ascending=False)\n",
        "        \n",
        "        print(\"\\nüìä TOP 10 FEATURES COMUNES:\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"{'Feature':<35} {'Global':<10} {'Cercanas':<10} {'Diferencia':<10}\")\n",
        "        print(\"=\"*80)\n",
        "        \n",
        "        for _, row in df_common.head(10).iterrows():\n",
        "            print(f\"{row['feature']:<35} {row['global_importance']:<10.4f} \"\n",
        "                  f\"{row['nearby_importance']:<10.4f} {row['difference']:>+9.4f}\")\n",
        "    \n",
        "    # Mostrar top features √∫nicas\n",
        "    global_unique = set(global_features) - set(nearby_features)\n",
        "    nearby_unique = set(nearby_features) - set(global_features)\n",
        "    \n",
        "    print(f\"\\nüåê Features √∫nicas del modelo GLOBAL: {len(global_unique)}\")\n",
        "    if global_unique and len(global_unique) < 20:\n",
        "        global_unique_top = df_global[df_global['feature'].isin(global_unique)].head(10)\n",
        "        for _, row in global_unique_top.iterrows():\n",
        "            print(f\"   {row['feature']}: {row['importance']:.4f}\")\n",
        "    \n",
        "    print(f\"\\nüîç Features √∫nicas del modelo CERCANAS: {len(nearby_unique)}\")\n",
        "    if nearby_unique and len(nearby_unique) < 20:\n",
        "        nearby_unique_top = df_nearby[df_nearby['feature'].isin(nearby_unique)].head(10)\n",
        "        for _, row in nearby_unique_top.iterrows():\n",
        "            print(f\"   {row['feature']}: {row['importance']:.4f}\")\n",
        "\n",
        "plot_feature_importance()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìà 4. Conclusiones y Pr√≥ximos Pasos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resumen final y recomendaciones\n",
        "def generate_final_report():\n",
        "    \"\"\"Genera un reporte final con conclusiones\"\"\"\n",
        "    \n",
        "    print(\"üéØ REPORTE FINAL - ENFOQUE SIMPLIFICADO\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    if global_model and nearby_model:\n",
        "        global_r2 = global_model['metrics']['val_r2']\n",
        "        nearby_r2 = nearby_model['metrics']['val_r2']\n",
        "        \n",
        "        print(f\"üéØ ESTACI√ìN OBJETIVO: 014 - Pacifico (m√°s concurrida)\")\n",
        "        print(f\"üìä PERFORMANCE GLOBAL: R¬≤ = {global_r2:.4f}\")\n",
        "        print(f\"üìä PERFORMANCE CERCANAS: R¬≤ = {nearby_r2:.4f}\")\n",
        "        \n",
        "        # Determinar el mejor modelo\n",
        "        if nearby_r2 > global_r2:\n",
        "            winner = \"ESTACIONES CERCANAS üîç\"\n",
        "            improvement = nearby_r2 - global_r2\n",
        "            print(f\"\\nüèÜ GANADOR: {winner}\")\n",
        "            print(f\"   Mejora de R¬≤: +{improvement:.4f}\")\n",
        "        elif global_r2 > nearby_r2:\n",
        "            winner = \"MODELO GLOBAL üåê\"\n",
        "            difference = global_r2 - nearby_r2\n",
        "            print(f\"\\nüèÜ GANADOR: {winner}\")\n",
        "            print(f\"   Ventaja de R¬≤: +{difference:.4f}\")\n",
        "        else:\n",
        "            print(f\"\\nü§ù EMPATE - Performance similar\")\n",
        "        \n",
        "        # An√°lisis de complejidad\n",
        "        global_features = len(global_model['features'])\n",
        "        nearby_features = len(nearby_model['features'])\n",
        "        reduction = (1 - nearby_features / global_features) * 100\n",
        "        \n",
        "        print(f\"\\nüìä COMPLEJIDAD DEL MODELO:\")\n",
        "        print(f\"   Global: {global_features} features\")\n",
        "        print(f\"   Cercanas: {nearby_features} features\")\n",
        "        print(f\"   Reducci√≥n: {reduction:.1f}%\")\n",
        "        \n",
        "    else:\n",
        "        print(\"‚ùå No se pudieron cargar ambos modelos para la comparaci√≥n\")\n",
        "    \n",
        "    print(f\"\\nüîÑ PR√ìXIMOS PASOS RECOMENDADOS:\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    print(\"1. üìà ESCALAMIENTO GRADUAL:\")\n",
        "    print(\"   - Entrenar para Top 2 estaciones m√°s concurridas\")\n",
        "    print(\"   - Entrenar para Top 5 estaciones m√°s concurridas\")\n",
        "    print(\"   - Evaluar en qu√© punto se degrada la performance\")\n",
        "    \n",
        "    print(\"\\n2. üîß OPTIMIZACI√ìN DE FEATURES:\")\n",
        "    print(\"   - Crear features espec√≠ficas para la estaci√≥n objetivo\")\n",
        "    print(\"   - Incorporar informaci√≥n de clima/eventos\")\n",
        "    print(\"   - Probar diferentes ventanas temporales (15min, 45min, 60min)\")\n",
        "    \n",
        "    print(\"\\n3. üéØ MEJORAS DEL MODELO:\")\n",
        "    print(\"   - Tuning de hiperpar√°metros con Grid/Random Search\")\n",
        "    print(\"   - Probar otros algoritmos (Random Forest, LightGBM)\")\n",
        "    print(\"   - Implementar ensemble de modelos\")\n",
        "    \n",
        "    print(\"\\n4. üß™ VALIDACI√ìN ADICIONAL:\")\n",
        "    print(\"   - Cross-validation temporal\")\n",
        "    print(\"   - Validaci√≥n en datos de test (Septiembre 2024+)\")\n",
        "    print(\"   - An√°lisis de estacionalidad y tendencias\")\n",
        "    \n",
        "    print(\"\\n5. üöÄ DEPLOYMENT:\")\n",
        "    print(\"   - Crear API para predicciones en tiempo real\")\n",
        "    print(\"   - Dashboard de monitoreo\")\n",
        "    print(\"   - Sistema de alertas por baja performance\")\n",
        "    \n",
        "    print(f\"\\n‚úÖ LOGROS DEL ENFOQUE SIMPLIFICADO:\")\n",
        "    print(\"   ‚úì Redujo complejidad del problema original\")\n",
        "    print(\"   ‚úì Estableci√≥ baseline s√≥lida para 1 estaci√≥n\")\n",
        "    print(\"   ‚úì Permiti√≥ identificar features m√°s relevantes\")\n",
        "    print(\"   ‚úì Facilit√≥ interpretabilidad del modelo\")\n",
        "    print(\"   ‚úì Cre√≥ framework escalable para m√∫ltiples estaciones\")\n",
        "\n",
        "generate_final_report()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
